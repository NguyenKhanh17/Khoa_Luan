<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation</title>
    <link rel="icon" href="/static/front_end_images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="styles_docs.css">
</head>
<body>
    <nav id="navbar">
        <div class="navbar-left">
            <img src="/static/front_end_images/logo.png" alt="SmartSwine Logo" class="logo">
            <span><a href="/" style="text-decoration: none;" id="navbar-title">SmartSwine</a></span>
        </div>
        <button class="menu-toggle" aria-label="Toggle Menu">â˜°</button>
        <ul class="navbar-menu">
            <li><a href="/overview" class="nav-overview">Overview</a></li>
            <li><a href="/solutions" class="nav-solutions">Solutions</a></li>
            <li><a href="/dashboard" class="nav-dashboard">Dashboard</a></li>
            <li><a href="/resources" class="nav-resources">Resources</a></li>
            <li><a href="/contact" class="nav-contact">Contact Us</a></li>
        </ul>
        <div class="navbar-right">
            <a href="/docs" class="nav-docs">Docs</a>
            <a href="/support" class="nav-support">Support</a>
            <div class="language-select">
                <select name="language" id="language-select">
                    <option value="en" selected>English</option>
                    <option value="vi">Vietnamese</option>
                    <option value="zh">Chinese</option>
                </select>
            </div>
        </div>
    </nav>
    <header>
        <h1>Documentation</h1>
    </header>
    <main>
        <section id = "introduction">
            <h2>Introduction</h2>
            <p>This page provides documentation for using our products and services.</p>
        </section>
        <section>
            <div class="container">
                <h1>Prediction Algorithms for DFI and Pig Weight</h1>
                <p class="intro">This page provides detailed information about the prediction algorithms used in the feed intake (DFI) and pig weight prediction system. These algorithms help increase the accuracy of prediction models and support users in selecting the most suitable method.</p>

                <div class="toc">
                    <h2>Table of Contents</h2>
                    <ul>
                        <li><a href="#linear-regression">Linear Regression</a></li>
                        <li><a href="#gradient-boosting">Gradient Boosting</a></li>
                        <li><a href="#knn-regression">K Nearest Neighbors Regression (KNN Regression)</a></li>
                        <li><a href="#xgboost-regressor">XGBoost Regressor</a></li>
                        <li><a href="#support-vector-regression">Support Vector Regression (SVR)</a></li>
                        <li><a href="#random-forest-regression">Random Forest Regression</a></li>
                        <li><a href="#long-short-term-memory">Long Short Term Memory</a></li>
                        <li><a href="#mlp-regressor">Multi-Layer Perceptron Regressor (MLP Regressor)</a></li>
                    </ul>
                </div>

                <section id="linear-regression">
                    <h2>1. Linear Regression</h2>
                    <p><strong>Description:</strong> Simplistic model assuming a linear relationship between variables, making it a baseline for predictive tasks.</p>
                    <p><strong>Application:</strong> Best suited for straightforward relationships like predicting basic feed consumption trends.</p>
                    <p><strong>Advantages:</strong> Easy to interpret, quick to implement.</p>
                    <p><strong>Limitations:</strong> Struggles with complex or non-linear patterns.</p>
                    <button class="view-more-btn" data-algorithm="linear-regression">View more</button>
                </section>

                <section id="gradient-boosting">
                    <h2>2. Gradient Boosting</h2>
                    <p><strong>Description:</strong> Combines weak learners to enhance prediction accuracy, often used for competitive tasks.</p>
                    <p><strong>Application:</strong> Ideal for capturing intricate patterns in feed and weight changes.</p>
                    <p><strong>Advantages:</strong> High accuracy, robust for complex datasets.</p>
                    <p><strong>Limitations:</strong> Computationally intensive, requires careful tuning.</p>
                    <button class="view-more-btn" data-algorithm="gradient-boosting">View more</button>
                </section>

                <section id="knn-regression">
                    <h2>3. K Nearest Neighbors Regression (KNN Regression)</h2>
                    <p><strong>Description:</strong> A non-parametric method that predicts outcomes based on the closest training examples in the feature space.</p>
                    <p><strong>Application:</strong> Useful for datasets with complex relationships where linear assumptions do not hold.</p>
                    <p><strong>Advantages:</strong> Simple to understand and implement, flexible to different data distributions.</p>
                    <p><strong>Limitations:</strong> Sensitive to irrelevant features and the choice of distance metric.</p>
                    <button class="view-more-btn" data-algorithm="knn-regression">View more</button>
                </section>

                <section id="xgboost-regressor">
                    <h2>4. XGBoost Regressor</h2>
                    <p><strong>Description:</strong> An efficient and scalable implementation of gradient boosting framework, designed for speed and performance.</p>
                    <p><strong>Application:</strong> Widely used for structured/tabular data, particularly in competitions and real-world applications.</p>
                    <p><strong>Advantages:</strong> High performance, handles missing values automatically, and includes regularization to prevent overfitting.</p>
                    <p><strong>Limitations:</strong> Can be complex to tune and may require careful feature engineering.</p>
                    <button class="view-more-btn" data-algorithm="xgboost-regressor">View more</button>
                </section>

                <section id="support-vector-regression">
                    <h2>5. Support Vector Regression (SVR)</h2>
                    <p><strong>Description:</strong> A type of Support Vector Machine that supports linear and non-linear regression.</p>
                    <p><strong>Application:</strong> Suitable for high-dimensional spaces and when the number of dimensions exceeds the number of samples.</p>
                    <p><strong>Advantages:</strong> Effective in high-dimensional spaces, robust against overfitting.</p>
                    <p><strong>Limitations:</strong> Less effective on very large datasets, requires careful tuning of parameters.</p>
                    <button class="view-more-btn" data-algorithm="support-vector-regression">View more</button>
                    </section>

                <section id="random-forest-regression">
                    <h2>6. Random Forest Regression</h2>
                    <p><strong>Description:</strong> An ensemble method that constructs multiple decision trees and merges them to get a more accurate and stable prediction.</p>
                    <p><strong>Application:</strong> Works well for both regression and classification tasks, especially with large datasets.</p>
                    <p><strong>Advantages:</strong> Reduces overfitting, handles missing values well.</p>
                    <p><strong>Limitations:</strong> Can be less interpretable than single decision trees, requires more computational resources.</p>
                    <button class="view-more-btn" data-algorithm="random-forest-regression">View more</button>
                </section>

                <section id="long-short-term-memory">
                    <h2>7. Long Short-Term Memory (LSTM)</h2>
                    <p><strong>Description:</strong> A specialized neural network adept at understanding sequential data, such as time-series feed intake.</p>
                    <p><strong>Application:</strong> Excellent for forecasting feed consumption or weight changes based on historical data.</p>
                    <p><strong>Advantages:</strong> Captures long-term dependencies effectively.</p>
                    <p><strong>Limitations:</strong> High data and resource requirements.</p>
                    <button class="view-more-btn" data-algorithm="long-short-term-memory">View more</button>
                </section>

                <section id="mlp-regressor">
                    <h2>8. Multi-Layer Perceptron Regressor (MLP Regressor)</h2>
                    <p><strong>Description:</strong> A type of neural network that consists of multiple layers of interconnected nodes, allowing for complex nonlinear relationships.</p>
                    <p><strong>Application:</strong> Suitable for tasks requiring nonlinear relationships, such as predicting feed intake or weight changes.</p>
                    <p><strong>Advantages:</strong> Highly flexible, capable of capturing complex patterns.</p>
                    <p><strong>Limitations:</strong> Requires significant data and computational resources, can be prone to overfitting.</p>
                    <button class="view-more-btn" data-algorithm="mlp-regressor">View more</button>
                </section>
            </div>
        </section>
    </main>


    <!-- Popup Container -->
    <div class="popup" id="popup" style="display: none;">
        <div class="popup-content">
            <button class="close-btn">&times;</button>
            <h2 id="popup-title">Title</h2>
            <p id="popup-description">Detailed description here...</p>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <p>&copy; 2024 SmartSwine. All rights reserved.</p>
    </footer>

    <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script src="./scripts_docs.js"></script>
</body>
</html>
